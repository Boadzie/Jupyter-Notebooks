{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentimental Analysis with LSTM and IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Boadzie/Jupyter-Notebooks/blob/master/Sentimental_Analysis_with_LSTM_and_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCdOuIyN9Rkb",
        "colab_type": "text"
      },
      "source": [
        "#Business Problem\n",
        "---\n",
        "**Predict Sentiment in Text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5v1OUyJ9tbe",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Get the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckBzT8tq9JgD",
        "colab_type": "code",
        "outputId": "d7c35b9c-cd6e-49e0-89f2-da420c328717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load keras libraries, layers and the imdb dataset\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "\n",
        "\n",
        "# decide maximum number of words to load in dataset\n",
        "max_features = 20000\n",
        "\n",
        "\n",
        "# decide maximum words in a sentence and batch size\n",
        "maxlen = 50\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7Wa5iuF9sHa",
        "colab_type": "code",
        "outputId": "ecb7b56e-1920-49cc-8463-7ec817375e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !pip install numpy==1.16.1\n",
        "import numpy as np\n",
        "\n",
        "# load the data\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IEEnmlL9sJ9",
        "colab_type": "code",
        "outputId": "01c96406-ee85-42dc-edd0-2b8f7f938440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# pad the sequences\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (25000, 50)\n",
            "x_test shape: (25000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIbBf-tl--49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAaWXd8N_HYQ",
        "colab_type": "text"
      },
      "source": [
        "### Explore the Text Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47NkfRxe9sO3",
        "colab_type": "code",
        "outputId": "1780da0e-d3fc-4c15-db9f-100f6bd67b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# show a data sample\n",
        "print(\"Sample of x_train array = \", x_train[0])\n",
        "print(\"Sample of y_train array = \", y_train[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample of x_train array =  [2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32]\n",
            "Sample of y_train array =  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzS4xIoU9sTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the vocabulary used for converting words to numbers\n",
        "imdb_vocab = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2vCKzi__Y98",
        "colab_type": "code",
        "outputId": "6830cf65-3d15-42fd-86c3-aeafb87389b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# create a small vocabulary with only top 20 items and print it\n",
        "# this is just to understand how the vocabulary looks\n",
        "small_vocab = { key:value for key, value in imdb_vocab.items() if value < 20 }\n",
        "print(\"Vocabulary = \", small_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary =  {'with': 16, 'i': 10, 'as': 14, 'it': 9, 'is': 6, 'in': 8, 'but': 18, 'of': 4, 'this': 11, 'a': 3, 'for': 15, 'br': 7, 'the': 1, 'was': 13, 'and': 2, 'to': 5, 'film': 19, 'movie': 17, 'that': 12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1provn9p_ZA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to get the sentence from integer array\n",
        "# reverse look-up words in vocabulary\n",
        "def get_original_text(int_arr):\n",
        "  word_to_id = {k:(v+3) for k,v in imdb_vocab.items()}\n",
        "  word_to_id[\"<PAD>\"] = 0\n",
        "  word_to_id[\"<START>\"] = 1\n",
        "  word_to_id[\"<UNK>\"] = 2\n",
        "  id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "  return ' '.join(id_to_word[id] for id in int_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E57xneDQ_Y68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define sentiments array\n",
        "sentiment_labels = ['Negative', 'Positive']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueZ9P9VL_jnc",
        "colab_type": "code",
        "outputId": "36bb7552-cde7-42a1-86a1-dbdbdf70156a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "print(\"-------------------------\")\n",
        "print(\"SOME SENTENCE AND SENTIMENT SAMPLES\")\n",
        "\n",
        "# print some of the training data\n",
        "for i in range(5):\n",
        "  print(\"Training Sentence = \", get_original_text(x_train[i]))\n",
        "  print(\"Sentiment = \", sentiment_labels[y_train[i]])\n",
        "  print(\"-----------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------\n",
            "SOME SENTENCE AND SENTIMENT SAMPLES\n",
            "Training Sentence =  grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
            "Sentiment =  Positive\n",
            "-----------------------\n",
            "Training Sentence =  boobs and <UNK> taking away bodies and the gym still doesn't close for <UNK> all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
            "Sentiment =  Negative\n",
            "-----------------------\n",
            "Training Sentence =  must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNK> this is to watch save yourself an hour a bit of your life\n",
            "Sentiment =  Negative\n",
            "-----------------------\n",
            "Training Sentence =  man to see a film that is true to scotland this one is probably unique if you maybe <UNK> on it deeply enough you might even re evaluate the power of storytelling and the age old question of whether there are some truths that cannot be told but only experienced\n",
            "Sentiment =  Positive\n",
            "-----------------------\n",
            "Training Sentence =  the <UNK> and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\n",
            "Sentiment =  Negative\n",
            "-----------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhPVVDbz_jsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjCzfP7C_vZC",
        "colab_type": "text"
      },
      "source": [
        "### Build and Train the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqWGAj6d_jwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW27bfQU_1it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ86JmPV_1lh",
        "colab_type": "code",
        "outputId": "1fdff8c7-33b3-490d-a8df-abfa7ce2d48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# train the model\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=2, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 126s 5ms/step - loss: 0.4594 - acc: 0.7753 - val_loss: 0.4333 - val_acc: 0.8023\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 120s 5ms/step - loss: 0.2954 - acc: 0.8764 - val_loss: 0.4213 - val_acc: 0.8124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffb73b8aa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRwxlCtV_1gT",
        "colab_type": "code",
        "outputId": "efc5cf69-01ab-4ee8-a482-1e6c37dff19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 21s 828us/step\n",
            "Test score: 0.4212919333076477\n",
            "Test accuracy: 0.8124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx7ZV6ML_1dD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVraYLHwAVUZ",
        "colab_type": "text"
      },
      "source": [
        "###  Make Predictions on Our Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbOvio4bAWy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "# first we will save the model\n",
        "model.save('imdb_nlp.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oylkD3D6AW2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the word index from imdb dataset\n",
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8C6tm5tAW6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the documents\n",
        "my_sentence1 = 'really bad experience. amazingly bad.'\n",
        "my_sentence2 = 'pretty awesome to see. very good work.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1ncuyQaAg_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define function to predict sentiment using model\n",
        "def predict_sentiment(my_test):\n",
        "  # tokenize the sentence\n",
        "  \n",
        "  word_sequence = text_to_word_sequence(my_test)\n",
        "  # create a blank sequence of integers\n",
        "  int_sequence = []\n",
        "  \n",
        "  # for each word in the sentence\n",
        "  for w in word_sequence:\n",
        "    # get the integer from word_index (vocabulary) and add to list\n",
        "    int_sequence.append(word_index[w])\n",
        "    \n",
        "  # pad the sequence of numbers to input size expected by model\n",
        "  sent_test = sequence.pad_sequences([int_sequence], maxlen=maxlen)\n",
        "    \n",
        "    # make a prediction using our Model\n",
        "  y_pred = model.predict(sent_test)\n",
        "  return y_pred[0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsfG9v6TAhC1",
        "colab_type": "code",
        "outputId": "47c43c42-cebd-4b1a-c9b1-ee1f59c6363c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# show results for sentences\n",
        "print ('SENTENCE : ', my_sentence1, ' : ', predict_sentiment(my_sentence1), ' : SENTIMENT : ', sentiment_labels[int(round(predict_sentiment(my_sentence1)))] )\n",
        "\n",
        "print ('SENTENCE : ', my_sentence2, ' : ', predict_sentiment(my_sentence2), ' : SENTIMENT : ', sentiment_labels[int(round(predict_sentiment(my_sentence2)))] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SENTENCE :  really bad experience. amazingly bad.  :  0.8836059  : SENTIMENT :  Positive\n",
            "SENTENCE :  pretty awesome to see. very good work.  :  0.17481722  : SENTIMENT :  Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pjMkDinAwPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj2-Z_X-AwXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}